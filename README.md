# Human-following Bot
#### Team members : [Adithyan Rajesh](https://github.com/Coiffed-Columbo "Github profile of Adithyan Rajesh"), [K S Varun](https://github.com/whos-bad "Github profile of K S Varun"), [Gouri S Dev](https://github.com/GouriSDev "Github profile of Gouri S Dev"), [Aditya Byju](https://github.com/Lazyy7 "Github profile of Aditya Byju")
## What is the project all about?
The idea of the project was to make a Human-following bot based on Computer Vision that uses the feed from its camera to find the coordinates of the human to be followed and uses this information to follow the human while maintaining a particular distance at all times. This bot can be developed into a luggage carrying robot, or be used for surveillance.

<div style="text-align:center"><img src="images%20and%20videos/sentinel%20bot.jpeg" width=600px/>
</div>
<h4>Robot model created using Solidworks - SENTINEL</h4>
<hr></hr>
<div style="text-align:center"><img src="images%20and%20videos/gazebo%20demo.gif" width=600px/>
</div>
<h4>SENTINEL following human using OpenCV and YOLO</h4>
<a href="images%20and%20videos/Human-following%20Bot%20demo.mp4" title="Video showing tracking of human by the bot in Gazebo">Video link</a></br>
Note: This works considering you have downloaded the weights file at the yolov3-coco directory inside of human detection directory. 
<hr></hr>
<div style="text-align:center"><img src="images%20and%20videos/openCV%20demo.jpg" width=600px/>
</div>
<h4>Detection of the custom accessory using OpenCV and YOLO</h4>
<a href="https://pysource.com/2020/04/02/train-yolo-to-detect-a-custom-object-online-with-free-gpu/" title="Tutorial showing how to detect a custom accessory using OpenCV and YOLO">Tutorial link</a>
<hr></hr>

<h3><a href="https://docs.google.com/document/d/1_7Y8IBTUtFv1acjY5ltlLoZ3GvdO9JTSVAz3Jc5b-h8">Final documentation link</a><h3>

### Skills Learnt
- Fundamentals of Python
- Version control using Git and managing repositories on Github
- Installation of Ubuntu and various useful Linux terminal commands
- Robot control using ROS and simulation in Gazebo
- Creating a robot model in Solidworks
- Darknet architecture and YOLO implementation
- Basics of image processing and Machine Learning while working with OpenCV and YOLO
- To train a custom dataset for detection


### References
- <a href="https://docs.google.com/document/d/1Zy8wdP_IZVClmJ4RQ8geuRMGNmiNQdbUKYD_cXuroik/edit" target="_blank">CUDA Installation procedure</a>
- <a href="https://docs.google.com/document/d/1cS2fPa2mSn4a64bqt6ewOZj7CbpALXwBtqBfHCxVn1c">Python Documentation</a>
- <a href="http://gazebosim.org/tutorials">Gazebo Tutorials</a>
- <a href="http://wiki.ros.org/">ROS Tutorials</a>
- <a href="https://github.com/erciitb/ROS-Tutorial">ROS Tutorials by ERC-IITB</a>
- <a href="https://github.com/iArunava/YOLOv3-Object-Detection-with-OpenCV">YOLOv3</a>
- <a href="https://www.youtube.com/watch?v=WQeoO7MI0Bs">Basics of OpenCV</a>
- <a href="https://rsl.ethz.ch/education-students/lectures/ros.html">ROS Tutorials by ETH Zurich</a>
- <a href="https://drive.google.com/drive/folders/16sAReKEfsDDJ01Y0PLDpkgZngDxLBVSO?usp=sharing">ERC-IITB ER-101 session link</a>
- <a href="https://pysource.com/2020/04/02/train-yolo-to-detect-a-custom-object-online-with-free-gpu/">Training YOLOv3 with Custom Dataset</a> 